{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "34b232e2",
   "metadata": {},
   "source": [
    "\n",
    "## Intelligent Architectures (5LIL0) Assignment 3\n",
    " \n",
    "<div style=\"display: flex; justify-content: center;\">\n",
    "    <figure style=\"background-color: lightgray; padding: 10px; display: inline-block; text-align: center;\">\n",
    "        <img src=\"./imgs/lab_3_overview.png\" alt=\"Overview of Lab 3\">\n",
    "        <figcaption><strong>Figure 1:</strong> Overview of Lab 3.</figcaption>\n",
    "    </figure>\n",
    "</div>\n",
    "\n",
    "\n",
    "\n",
    "### Simulating a digital hardware convolution accelerator\n",
    "\n",
    "### Introduction:\n",
    " \n",
    "The main objective of this lab is to **simulate the digital hardware implementation of a convolution accelerator**. To achieve this goal you will learn how to transition from software simulations of simple neural networks to their implementations in custom digital hardware. Furthermore, you will be provided with an input-reuse dataflow accellerator implementation and will be asked to implement a weight-reuse version of it. These concepts will be treaded in lecture \"DNN HW design principles & efficient dataflow\" and you will need those for the second part of the assigment. So don't worry if now don't sound familiar you will know it very soon.\n",
    "\n",
    "This lab is divided into two parts: **Lab 3A (Software Simulation)** and **Lab 3B (Hardware Simulation)**, as illustrated in the provided diagram. Each part focuses on specific aspects of transitioning a neural network from software to hardware.\n",
    "\n",
    "The workflow above explains the process of transitioning neural networks from software simulations to hardware implementations, using Icarus Verilog as a tool for hardware simulation and PyTorch as a tool for exporting the network. Verilog is a hardware description language (HDL) commonly used to design and simulate digital systems, such as custom accelerators for neural networks. For this exercise we will use System Veriog instead of plain Verilog. System Verilog is simply and extension of Verilog with similified datatypes, multi-dimensional arrays and object oriented programming. Iverilog is a widely used open-source simulator for Verilog/System Verilog that allows you to design digital harware and verify its functionality and performance before physical implementation. \n",
    " \n",
    "\n",
    "In **Lab 3A**, you will first load a pre-trained neural network (consisting of convolutional and fully connected layers) and evaluate its performance on the MNIST dataset in PyTorch at full precision (FP32) to establish a baseline. In hardware implementations, lower precision formats, such as 4-bit or 8-bit fixed-point representations, are preferred over the standard FP32 used in software. Operating at lower precision significantly reduces memory consumption and computational complexity, enabling faster processing and lower energy consumption, all critical factors in hardware design. As the main goal is to design and test an hardware accellerator for the convolutional part of the network, you will quantize only the kernel values of the convolution to 4-bit fixed-point (INT4), while keeping the rest of the network to FP32. For the hardware simulation of the convolution operations, the quantized kernel values must be loaded in the multi-dimensional arrays defined in System Verilog. To do so, you will export the quantized model's parameters of the convolutional layer into memory initialization files (.mem) compatible with hardware simulator. Notably, these files must be in a specific format and you will be asked to write a conversion function that stores the quantized parameters in a suitable form for .mem files. \n",
    "\n",
    "\n",
    "In **Lab 3B**, these exported memory initialization files will be loaded into the multi-dimensional array hosting the kernels of the convolution accelerator. You will then count the clock cycles required to perform the full convolution using the provided convolutional accelerator with input-reuse dataflow. After this, you will implement a weight-reuse dataflow and measure the clock cycles again to compare performance. To measure the number of clock-cycles you will use GTKWave, a waveform visualization tool used to analyze signals in hardware simulations.\n",
    "\n",
    " \n",
    "Through this workflow, you will gain hands-on experience with the practical considerations of moving from software to hardware, including the use of HDLs like Verilog, the benefits of quantization, and the trade-offs involved in custom digital accelerator design. Specifically, the boxes in blue in the image above must be implemented by you while the others will be provided. **Thus, in this lab you will learn how to:**\n",
    " \n",
    "**1. Export kernel parameters into a file suitable for memory initialization of multi-dimensional arrays of hardware simulation.**\n",
    "\n",
    "**2. Load these files into the simulated memory using System Verilog with Icarus compiler.**\n",
    "\n",
    "**3. Implement a weight stationary dataflow convolutional accelerator.**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0edb77d9",
   "metadata": {},
   "source": [
    "## Part A: Loading pre-trained model and exporting weights\n",
    "\n",
    "The main steps of this section are:\n",
    "\n",
    "1. Create a convolution + fully connected model class \n",
    "2. Load the pre-trained parameters from the .pth file \n",
    "3. Measure the test accuracy of the model using FP32 on the MNIST dataset\n",
    "4. Quantize the weights to INT8 and measure the accuracy drop \n",
    "5. Export the quantized weights to a memory initialization file (.mem) for memory initialization in verilog\n",
    "\n",
    "The blue steps in the Figure 1 above indicate the parts you need to complete. \n",
    "\n",
    "## Steps 1 & 2 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "90c67a7b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "simple_CNN(\n",
       "  (conv): Conv2d(1, 3, kernel_size=(3, 3), stride=(1, 1), bias=False)\n",
       "  (relu): ReLU()\n",
       "  (mlp): Linear(in_features=2028, out_features=10, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Ensure reproducibility across CO machines\n",
    "import os \n",
    "os.environ[\"OPENBLAS_NUM_THREADS\"] = \"1\"\n",
    "os.environ[\"MKL_NUM_THREADS\"] = \"1\"\n",
    "os.environ[\"OMP_NUM_THREADS\"] = \"1\"\n",
    "os.environ[\"NUMEXPR_NUM_THREADS\"] = \"1\"\n",
    "os.environ[\"MKL_CBWR\"] = \"COMPATIBLE\"\n",
    "\n",
    "# Import required packages \n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader\n",
    "import copy\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "np.random.seed(seed=0)\n",
    "torch.manual_seed(0)\n",
    "\n",
    "# Set the torch device to use cpu \n",
    "device = torch.device(\"cpu\")\n",
    "\n",
    "# Class definition of the model\n",
    "output_chan = 3\n",
    "class simple_CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(simple_CNN, self).__init__()\n",
    "        self.conv = nn.Conv2d(in_channels=1, out_channels=output_chan, kernel_size=3, stride=1, padding=0, bias=False)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.mlp = nn.Linear(26*26*output_chan, 10, bias=False)\n",
    "\n",
    "        torch.manual_seed(42)\n",
    "        nn.init.xavier_uniform_(self.conv.weight)\n",
    "        nn.init.xavier_uniform_(self.mlp.weight)\n",
    "\n",
    "    def forward(self, x):\n",
    "\n",
    "\n",
    "        # Here you need to implement the convolutional layer\n",
    "        x = self.conv(x)\n",
    "        h1 = self.relu(x)\n",
    "        h1 = h1.view(h1.shape[0], -1)\n",
    "        output = self.mlp(h1)\n",
    "        \n",
    "        \"\"\"Pass the input throgh the network\"\"\"\n",
    "        return output\n",
    "\n",
    "\n",
    "# Load pre-trained kernels into the model \n",
    "model = simple_CNN().to(device)\n",
    "state_dict = torch.load('./simple_CNN.pth', weights_only=True)\n",
    "\n",
    "\n",
    "# Load into the model\n",
    "model.load_state_dict(state_dict)\n",
    "model.eval().to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc3c4ca1",
   "metadata": {},
   "source": [
    "## Step 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7d014d0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy 0.9648\n",
      "The correct Accuracy should be: 0.9648\n"
     ]
    }
   ],
   "source": [
    "# Load the MNIST datasets\n",
    "def binarize(image):\n",
    "    return (image > 0.5).float()\n",
    "\n",
    "transform = transforms.Compose([transforms.ToTensor(), transforms.Lambda(binarize)])\n",
    "test_dataset = datasets.MNIST(root='./data', train=False, transform=transform, download=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=64, shuffle=False)\n",
    "\n",
    "# Create a test function to measure accuracy \n",
    "def test(model, test_loader):\n",
    "    model.eval()\n",
    "    correct_cases = 0\n",
    "    for batch_idx, (data, target) in enumerate(test_loader):\n",
    "        output = model(data.to(device))\n",
    "        target = target.to(device)\n",
    "        correct_cases += (output.argmax(1) == target).sum().item()\n",
    "    \n",
    "    print(f'Accuracy {correct_cases/len(test_loader.dataset)}')\n",
    "\n",
    "test(model, test_loader)\n",
    "print(f\"The correct Accuracy should be: 0.9648\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba0dcadf",
   "metadata": {},
   "source": [
    "## Step 4\n",
    "\n",
    "In the previous steps we created a model class and initialized the kernels with the pre-trained values of simple_CNN.pth. Now, the goal is to create a version of the model with quantized weights (post-training quantization) and measure the test accuracy. To acheive this goal we take the pre-train kernels and quantize them to integer precision of 4 bits. \n",
    "\n",
    "Use the following code and quantize the weight to the range [-8,7] with 4 bit resolution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4269c850",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy 0.9626\n"
     ]
    }
   ],
   "source": [
    "def lower_precision(model, bits=8):\n",
    "    model_copy = copy.deepcopy(model)\n",
    "    for param in model_copy.parameters():\n",
    "        param.data = (param.data * 2**(bits-1)).round().clamp(-2**(bits - 1), 2**(bits - 1) - 1)\n",
    "    return model_copy\n",
    "\n",
    "low_prec_model = lower_precision(model, bits=4)\n",
    "low_prec_model.eval()\n",
    "test(low_prec_model, test_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d0fe5e7",
   "metadata": {},
   "source": [
    "## Step 5\n",
    "\n",
    "Now, we need to export the quantized weights into a format suitable for memory initialization in our hardware simulation. In SystemVerilog, multi-dimensional arrays store these quantized weights and are initialized when an instance of the convolution accelerator is created.\n",
    "\n",
    "To determine the correct format (**hexadecimal two complement format**) and ordering of kernel values in the memory file (**KERNEL, ROW, COLUMN**), refer to the input-reuse module description ([`src/input_reuse.sv`](src/input_reuse.sv)). Since SystemVerilog expects values in either binary or hexadecimal format, your task in this section is to generate a  [`kernel.mem`](.mem)  file containing the quantized weights in the appropriate format.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "916c1edd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['4', '4', '4', 'C', 'E', '3', 'C', 'C', 'C']\n",
      "The first 9 correct results of manually conversion is ['4', '4', '4', 'C', 'E', '3', 'C', 'C', 'C']\n"
     ]
    }
   ],
   "source": [
    "# (TODO: Remove in handout: only used to generate golden files)\n",
    "# goldens = enumerate(test_loader)\n",
    "# batch_idx, (golden_datas, golden_targets) = next(goldens)\n",
    "# golden_data = golden_datas[0].unsqueeze(0)\n",
    "\n",
    "# golden_target = golden_targets[0]\n",
    "# golden_result = low_prec_model(golden_data.to(\"cpu\"))\n",
    "\n",
    "\n",
    "# TODO: FOLLOWING DONE BY STUDENTS \n",
    "golden_weights = low_prec_model.conv.weight.flatten().detach().numpy().astype(np.int32)\n",
    "\n",
    "def memory_init_file_gen(weights, file_path, bits=4):\n",
    "\n",
    "    # TODO: STUDENT PART {\n",
    "    def to_hexa_complement(value, bits):\n",
    "        \"\"\"Converts an integer to its hexadecimal two's complement representation.\"\"\"\n",
    "        ## TO DO CONVERT AN INTEGER TO ITS HEXDEC 2's COMP AND RETURN\n",
    "        if value < 0:\n",
    "            value += (1 << bits)\n",
    "        return hex(value)[2:].upper()\n",
    "        \n",
    "    binary_weights = [to_hexa_complement(w, bits) for w in weights]\n",
    "\n",
    "    with open(file_path, 'w') as f:\n",
    "        for weight in weights:\n",
    "            f.write(to_hexa_complement(weight, bits) + '\\n')\n",
    "\n",
    "    return binary_weights\n",
    "\n",
    "binary_weights = memory_init_file_gen(golden_weights, './src/files/golden_kernel.mem', bits=4)\n",
    "\n",
    "        \n",
    "print(binary_weights[:9])\n",
    "print(f\"The first 9 correct results of manually conversion is ['4', '4', '4', 'C', 'E', '3', 'C', 'C', 'C']\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cba2bb3",
   "metadata": {},
   "source": [
    "## Step 6\n",
    "\n",
    "Now, to get familiar with hardware design, you are asked to write a module and a testbench in SystemVerilog.\n",
    "The module gets as input a 96-bits string and find a match in the file, it returns the starting memory position of the match, -1 if not found.\n",
    "\n",
    "Also, please make a testbench that test the following strings \"11111111 11111111 11111111 11101110 11111111 11111111 11111111 11110100 11111111 11111111 11111111 11111100\" in what position is it located?\n",
    "\n",
    "**Note that you should connect to the coX machines and run the SystemVerilog modules and testbenches in there! For this process you should refer to the lecture slides or to Part B of this lab.**\n",
    "\n",
    "**The following two cells are snippet of SystemVerilog code (for your reference)**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26c0fe88",
   "metadata": {},
   "source": [
    "```systemverilog\n",
    "## SYSTEM VERILOG MODULE TEMPLATE - for your reference and to be saved in string_match.sv\n",
    "module string_match (\n",
    "    input logic clk,\n",
    "    input logic rst,\n",
    "    input logic [95:0] search_string,  // 96-bit input string\n",
    "    output logic found,                // 1 if found, 0 if not found\n",
    "    output logic signed [31:0] position // Start position of match (-1 if not found)\n",
    ");\n",
    "\n",
    "    localparam MEMORY_SIZE = 2028;  // Example memory size (32-bit words)\n",
    "    logic [31:0] memory [0:MEMORY_SIZE-1]; // Memory array (32-bit words)\n",
    "\n",
    "    initial begin\n",
    "        // Load data from file into memory\n",
    "        $readmemh(\"golden_conv.mem\", memory);\n",
    "    end\n",
    "\n",
    "\n",
    "    // TO DO COMPLETE\n",
    "    logic [31:0] search_word0, search_word1, search_word2;\n",
    "    assign search_word0 = search_string[31:0];\n",
    "    assign search_word1 = search_string[63:32];\n",
    "    assign search_word2 = search_string[95:64];\n",
    "\n",
    "    always_ff @(posedge clk or posedge rst) begin\n",
    "        if (rst) begin\n",
    "            found <= 0;\n",
    "            position <= -1;\n",
    "        end else begin\n",
    "            found <= 0;\n",
    "            position <= -1;\n",
    "            for (int i = 0; i < MEMORY_SIZE - 2; i++) begin\n",
    "                if (memory[i] == search_word2 && memory[i+1] == search_word1 && memory[i+2] == search_word0) begin\n",
    "                    found <= 1;\n",
    "                    position <= i;\n",
    "                    break;\n",
    "                end\n",
    "            end\n",
    "        end\n",
    "    // TO DO COMPLETE\n",
    "    end\n",
    "endmodule\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a208442c",
   "metadata": {},
   "source": [
    "```systemverilog\n",
    "## SYSTEM VERILOG TESTBENCH TEMPLATE - for your reference and to be saved in string_match_tb.sv\n",
    "module string_match_tb;\n",
    "\n",
    "    logic clk;\n",
    "    logic rst;\n",
    "    logic [95:0] search_string;\n",
    "    logic found;\n",
    "    logic signed [31:0] position;\n",
    "\n",
    "    // TO INSTANTIATE THE MODULE\n",
    "    string_match uut (\n",
    "        .clk(clk),\n",
    "        .rst(rst),\n",
    "        .search_string(search_string),\n",
    "        .found(found),\n",
    "        .position(position)\n",
    "    );\n",
    "\n",
    "    // Clock generation\n",
    "    always #5 clk = ~clk;\n",
    "\n",
    "    initial begin\n",
    "        // -------------\n",
    "        clk = 0;\n",
    "        rst = 1;\n",
    "        #10 rst = 0;\n",
    "        // -------------\n",
    "        \n",
    "        // Test input string (concatenation of three 32-bit words)\n",
    "        search_string = 96'b11111111111111111111111111101110_11111111111111111111111111110100_11111111111111111111111111111100;\n",
    "\n",
    "        // TO DO COMPLETE \n",
    "        #20;\n",
    "        \n",
    "        // Display results\n",
    "        if (found)\n",
    "            $display(\"Match found at position: %d (in 32-bit words)\", position);\n",
    "        else\n",
    "            $display(\"Match not found.\");\n",
    "\n",
    "    end\n",
    "endmodule\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d6c7f76",
   "metadata": {},
   "source": [
    "expected output ->   Match found at position: ??? (in 32-bit words)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b507a006",
   "metadata": {},
   "source": [
    "***Please note that the testbench output of part A could be a quiz question in canvas***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "900f74ef",
   "metadata": {},
   "source": [
    "## Part B: Hardware Accelerator Simulation \n",
    "\n",
    "In Part A of this lab, you quantized the convolutional layer's kernels to INT4 and exported them as a memory initialization file (.mem) for use in hardware simulation. Now, in Part B, you will focus on understanding the hardware simulation process. You will begin by exploring how hardware is described using System Verilog and how to compile it using Icarus Verilog (Iverilog). Then, you will simulate the hardware's behavior and analyze waveforms using GTKWave. Additionally, you will study different dataflow strategies, such as input-reuse and weight-reuse, as introduced in the accompanying slides. To make you life easier, an input-reuse module will be provided. Your task is to implement a weight-reuse version of this module, applying the concepts discussed in class.\n",
    "\n",
    "Notably, this lab primarily involves working with the Linux shell rather than Python. This provides an excellent opportunity to improve your command-line skills, which are fundamental for any form of hardware design.\n",
    "\n",
    "### Harware Simulation Flow\n",
    "Three tools are necessary for running hardware simulations: **Icarus verilog** to compile the system verilog descriptions of the hardware; **vvp** to run a simulation of the hardware and **GTKwave** to visualize the waveforms. The standard flow to move from harware description language (.sv) to simulation and waveform viewing is illustrated in Figure 2 below.\n",
    "\n",
    "As you can see, the inputs to the Icarus Verilog compiler are two: \n",
    "\n",
    "- **testbench.sv** -> provides and environment to simulate and verify the functionality of the module.sv (also referred to as Device Under Test or DUT) by providing inputs (such as memory init files) and monitor its output.\n",
    "- **module.sv** -> the file defining the actual hardware module (e.g. a convolution accelerator). \n",
    "\n",
    "<div style=\"background-color: lightgray; text-align: center; padding: 10px;\">\n",
    "    <figure style=\"margin: 0;\">\n",
    "        <img src=\"imgs/hw_toolchain.png\" alt=\"Image description\" style=\"display: inline-block;\">\n",
    "        <figcaption style=\"color: black;\"><strong>Figure 2: Toolchain</strong> </figcaption>\n",
    "    </figure>\n",
    "</div>\n",
    "\n",
    "### Directory organization\n",
    "\n",
    "Inside **/src** directory you will find the following files: \n",
    "\n",
    "- **input_reuse.sv** -> module definition of the convolution accelerator using input reuse \n",
    "- **testbench.sv** -> testbench for the module \n",
    "\n",
    "\n",
    "Inside the **/src/files** directory you can find the following: \n",
    "\n",
    "- **golden_output.mem** -> memory initialization file to verify matching of the hardware convolution with the software \n",
    "- **golden_input.mem** -> memory initialization file for the image\n",
    "- **golden_kernel.mem** -> memory initialization file for the kernel (generated in Part A)\n",
    "\n",
    "Note that there is no need for you to modify any of these memory initialization files as they are only used to ensure you have a match between the software simulation and the hardware simulation. \n",
    "\n",
    "\n",
    "### Input-reuse CNN accelerator example\n",
    "\n",
    " \n",
    "<div style=\"display: flex; justify-content: center;\">\n",
    "    <figure style=\"background-color: lightgray; padding: 10px; display: inline-block; text-align: center;\">\n",
    "        <img src=\"./imgs/input_reuse.png\" alt=\"Overview of Lab 3\">\n",
    "        <figcaption style=\"color: black;\"><strong>Figure 3: Input-reuse</strong> </figcaption>\n",
    "    </figure>\n",
    "</div>\n",
    "\n",
    "\n",
    "In this section you will learn how to run the example for the input-reuse dataflow accelerator depicted in Figure 3, where red represents memory modules, yellow denotes buffers, and blue compute units. As you can see, for the input-reuse, a window of the input image is loaded into the buffer from the main memory, while the kernel are streamed to the convolution compute unit. You should investigate the **testbench.sv** to understand how memory initialization files are loaded and how we interact with the convolutional module defined in **input_reuse.sv**. \n",
    "\n",
    "The procedure to run a full simulation and open the GTK wave is as follows: \n",
    "\n",
    "1. Log-in to CO machines ensuring graphical forwarding is enabled as explained in the lecture.\n",
    "2. Compile both the module and the testbench by running `iverilog -g2012 -o out ./src/testbench.sv ./src/input_reuse.sv`. The output of this command is the `out` file which can be used for simulation in the next step. \n",
    "3. Simulate the testbench by running `vvp out`. This commnand runs the simulations and creates a `waveform.vcd` file which can be used to visualize the waves. \n",
    "4. To observe the simulation waveforms run `gtkwave waveform.vcd`\n",
    "5. Open the GTKwave and learn how to use cursors to measure time differences (question about this will be in the quizz)\n",
    "\n",
    "Notably, the simulation will print matching between the convolution results obtained in software and stored in (golden_conv.mem) with the output of the convolution in the hardware simulation.\n",
    "### Weight-reuse CNN accelerator example\n",
    "\n",
    "<div style=\"display: flex; justify-content: center;\">\n",
    "    <figure style=\"background-color: lightgray; padding: 10px; display: inline-block; text-align: center;\">\n",
    "        <img src=\"./imgs/weight_reuse.png\" alt=\"Overview of Lab 3\">\n",
    "        <figcaption style=\"color: black;\"><strong>Figure 4: Weight-reuse</strong> </figcaption>\n",
    "    </figure>\n",
    "</div>\n",
    "\n",
    "\n",
    "In the previous section, you explored the hardware simulation flow and gained hands-on experience with an input-reuse dataflow accelerator. Now, it's time for the most exciting part of this lab: designing your own convolution accelerator with weight-reuse. As depicted in Figure 4, for the weight-reuse, the kernels must be loaded from memory to the buffer while the image is streamed duirectly from memory to the convolution processing. \n",
    "\n",
    "To accomplish this, you will need to:\n",
    "\n",
    "1. Create a new file named **weight_reuse.sv**, where you will define your weight-reuse accelerator.\n",
    "2. Modify **testbench.sv** to integrate and test your newly implemented module.\n",
    "3. Ensure that all convolution results match.\n",
    "4. Upload the **weight_reuse.sv** in the canvas assignment page. \n",
    "   \n",
    "This step will allow you to compare different dataflow strategies and gain a deeper understanding of hardware-efficient convolution operations. \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
