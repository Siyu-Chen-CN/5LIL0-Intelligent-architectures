{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "81f47b68-6931-4b5c-b542-f72a3a38716b",
   "metadata": {},
   "source": [
    "# Intelligent Architectures (5LIL0) Assignment 2 (version 0.1)\n",
    "\n",
    "#### **Authors:** [Alexios Balatsoukas-Stimming](mailto:a.k.balatsoukas.stimming@tue.nl) (TU/e), [Hiram Rayo Torres Rodriguez](mailto:hiram.rayotorresrodriguez@nxp.com) (NXP), [Willem Sanberg](mailto:willem.sanberg@nxp.com) (NXP)\n",
    "\n",
    "#### **License:** [CC BY-NC-SA 4.0](https://creativecommons.org/licenses/by-nc-sa/4.0/)\n",
    "\n",
    "## Part B: Neural Architecture Search\n",
    "\n",
    "In this part of the assignment, you will perform neural architecture search (NAS). As a NAS tool, you will use [Optuna](https://optuna.org/), which is a general framework for automated hyperparameter tuning and optimization. Contrary to previous assignments, the focus will be more on interpreting results rather than writing your own code. Also, we will use TensorFlow with the Keras front-end instead of PyTorch for the neural network operations. Finally, we will rely more on the confidence and independence you have developed through previous assignments (e.g., we may point you to online documentation for certain points rather than explaining all details).\n",
    "\n",
    "## 1. Setting up the NAS Experiment\n",
    "\n",
    "The class ``NASNet``, which is defined in the separate file ``NASNet.py``, contains various pre-implemented functions that are used to evaluate the performance of each NAS round, which is called a ``trial`` in Optuna terminology. In the table below is a list of the most important functions and their functionality:\n",
    "\n",
    "| Name | Functionality |\n",
    "| ------------- | ------------- |\n",
    "| ``__call__`` | Called when a class object is instantiated, performs training and calculates the optimization metrics |\n",
    "| ``_get_mnist_dataset`` | Loads and normalizes the MNIST dataset |\n",
    "| ``_quantize_model`` | Quantizes model using [LiteRT](https://ai.google.dev/edge/litert) using 8-bit full-integer quantization |\n",
    "| ``_evaluate_quantized_model`` | Calculates the accuracy of the quantized model |\n",
    "| ``_profile_model_latency`` | Calculates quantized model latency using the [Vela compiler](https://pypi.org/project/ethos-u-vela/) for an [ARM Ethos U55 NPU](https://armkeil.blob.core.windows.net/developer/Files/pdf/product-brief/arm-ethos-u55-product-brief.pdf) target |\n",
    "\n",
    "\n",
    "Let us now import the class and other packages that are required for this assignment (you can ignore any warnings/errors you see)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7f48b3fc-7afa-4d6d-8243-f087d8834a92",
   "metadata": {},
   "outputs": [],
   "source": [
    "from NASNet import NASNet\n",
    "import tensorflow as tf\n",
    "import logging\n",
    "import optuna\n",
    "from optuna.storages import JournalStorage\n",
    "from optuna.storages.journal import JournalFileBackend\n",
    "from optuna.samplers import TPESampler\n",
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"\"  # delete line to enable GPU-based training\n",
    "os.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = \"3\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8aef5cac-59f8-4312-a59b-b705f5418dad",
   "metadata": {},
   "source": [
    "Certain functionality was omitted from the NASNet class and we will implement it and add it to the class definition. First, a function is required to define the structure of the neural network to be optimized. We will implement a neural network for the MNIST dataset in Keras that looks as follows:\n",
    "\n",
    "Input (28x28 image, 1 channel) &rarr; Convolutional Layer (``num_filters`` filters, ``k_size``x``k_size`` filter size) &rarr; Batch Normalization Layer &rarr; ReLU activation &rarr; Dense Layer (``n_units`` neurons, ReLU activation) &rarr; Dense Layer (10 neurons, no activation) \n",
    "\n",
    "Note that ``num_filters``, ``k_size``, and ``n_units`` are parameters that will be optimized by Optuna. They can be accessed, for example for ``num_filters``, as ``self.trial_hp[\"num_filters\"]`` in the function below. Detailed documentation for Keras layers can be found [here](https://keras.io/api/layers/) and an explanation of the functional API to help you with the syntax can be found [here](https://keras.io/guides/functional_api/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "16e4de83-3409-4242-8dfc-50e74f8d38de",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _get_CNN(self, batch_size=256, training=True):\n",
    "    inputs = tf.keras.Input(shape=(28, 28, 1), batch_size=batch_size)\n",
    "\n",
    "    x = tf.keras.layers.Conv2D(filters=self.trial_hp[\"num_filters\"], \n",
    "                               kernel_size=(self.trial_hp[\"k_size\"], self.trial_hp[\"k_size\"]), \n",
    "                               padding=\"same\")(inputs)\n",
    "    x = tf.keras.layers.BatchNormalization()(x)\n",
    "    x = tf.keras.layers.ReLU()(x)\n",
    "    x = tf.keras.layers.Flatten()(x)\n",
    "    x = tf.keras.layers.Dense(units=self.trial_hp[\"n_units\"], activation=\"relu\")(x)\n",
    "\n",
    "    outputs = tf.keras.layers.Dense(10)(x)\n",
    "        \n",
    "    return tf.keras.Model(inputs=inputs,outputs=outputs)\n",
    "\n",
    "# Add function to class\n",
    "NASNet._get_CNN = _get_CNN"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac3d9d9b-546b-4587-8045-4388e0117358",
   "metadata": {},
   "source": [
    "Next, we need to define the search space for our three hyperparameters to guide the NAS procedure. This is done by simply calling (no return argument required) the ``trial.suggest_int`` function for each of the three named hyperparameters we used in the neural network definiton above (i.e., ``\"num_filters\"``, ``\"n_units\"`` and ``\"k_size\"``). You will find documentation and examples for this function [here](https://optuna.readthedocs.io/en/stable/reference/generated/optuna.trial.Trial.html#optuna.trial.Trial.suggest_int). The ranges for ``\"num_filters\"``, ``\"n_units\"`` and ``\"k_size\"`` should be [2,8], [4,16], and [3,9], respectively, with a step size of 2 for all hyperparameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "969911a1-0e2a-4674-8480-341435b92859",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _search_space_by_func(self, trial):\n",
    "        # search for kernel size, number of output features and neurons\n",
    "        trial.suggest_int(\"num_filters\", 2, 8, step=2)\n",
    "        trial.suggest_int(\"n_units\", 4, 16, step=2)\n",
    "        trial.suggest_int(\"k_size\", 3, 9, step=2)\n",
    "        return trial.params\n",
    "\n",
    "# Add function to class\n",
    "NASNet._search_space_by_func = _search_space_by_func"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76963836-631f-472f-b7cb-4db85d9d94fa",
   "metadata": {},
   "source": [
    "## 2. Running the NAS Experiment\n",
    "\n",
    "Before running our NAS experiment, we need to define a name for it that will be used as a folder name for the results. More importantly, we need to define the objectives of the optimization, which in our case are the floating-point accuracy (``fp32_accuracy``) and the number of parameters in the neural network (``num_params``), which we want to maximize and minimize, respectively. These metrics are calculated in the ``__call__`` function of the ``NASNet`` class. We also define the number of training epochs (``epochs = 1`` to keep the runtime of the experiment reasonable) and the learning rate (``lr = 0.001``).\n",
    "\n",
    "Running this cell with the default values will take approximately 10 minutes. If you need to experiment to verify your code, you can set ``n_trials = 1`` temporarily to run the code in a few seconds. Don't forget to set it back to ``n_trials = 50`` before running the final experiment.\n",
    "\n",
    "If you are interested, you can read the outputs that are printed, but this is not necessary. We will visualize and interpret the results in the following section. If the output of the cell becomes too long making it difficult for you to work, you can right click on it and select \"Clear Cell Output\" after it has finished running."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8af64e01-dd10-4de5-870d-e547289fdb9c",
   "metadata": {},
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "[WinError 1314] A required privilege is not held by the client: 'd:\\\\git\\\\5LIL0-Intelligent-architectures\\\\assignments\\\\assignment2_partB\\\\mnist_nas\\\\journal.log' -> 'd:\\\\git\\\\5LIL0-Intelligent-architectures\\\\assignments\\\\assignment2_partB\\\\mnist_nas\\\\journal.log.lock'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 24\u001b[0m\n\u001b[0;32m     22\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:    \n\u001b[0;32m     23\u001b[0m     \u001b[38;5;28;01mpass\u001b[39;00m    \n\u001b[1;32m---> 24\u001b[0m study \u001b[38;5;241m=\u001b[39m \u001b[43moptuna\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate_study\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     25\u001b[0m \u001b[43m    \u001b[49m\u001b[43msampler\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msampler\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     26\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstudy_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mexp_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     27\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mJournalStorage\u001b[49m\u001b[43m(\u001b[49m\u001b[43mJournalFileBackend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpath\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjoin\u001b[49m\u001b[43m(\u001b[49m\u001b[43mexp_dir\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mjournal.log\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     28\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# storage = \"sqlite:///mnist_nas.db\",\u001b[39;49;00m\n\u001b[0;32m     29\u001b[0m \u001b[43m    \u001b[49m\u001b[43mload_if_exists\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m     30\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdirections\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdirections\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     31\u001b[0m \u001b[43m)\u001b[49m\n\u001b[0;32m     33\u001b[0m \u001b[38;5;66;03m# perform NAS\u001b[39;00m\n\u001b[0;32m     34\u001b[0m study\u001b[38;5;241m.\u001b[39moptimize(NASNet(epochs\u001b[38;5;241m=\u001b[39mepochs, lr\u001b[38;5;241m=\u001b[39mlr, exp_dir\u001b[38;5;241m=\u001b[39mexp_dir, objectives\u001b[38;5;241m=\u001b[39mobjectives), n_trials\u001b[38;5;241m=\u001b[39mn_trials)\n",
      "File \u001b[1;32mc:\\Users\\SiyuC\\.conda\\envs\\ml\\lib\\site-packages\\optuna\\_convert_positional_args.py:83\u001b[0m, in \u001b[0;36mconvert_positional_args.<locals>.converter_decorator.<locals>.converter_wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     77\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\n\u001b[0;32m     78\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m() got multiple values for arguments \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mduplicated_kwds\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     79\u001b[0m     )\n\u001b[0;32m     81\u001b[0m kwargs\u001b[38;5;241m.\u001b[39mupdate(inferred_kwargs)\n\u001b[1;32m---> 83\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\SiyuC\\.conda\\envs\\ml\\lib\\site-packages\\optuna\\study\\study.py:1265\u001b[0m, in \u001b[0;36mcreate_study\u001b[1;34m(storage, sampler, pruner, study_name, direction, load_if_exists, directions)\u001b[0m\n\u001b[0;32m   1263\u001b[0m storage \u001b[38;5;241m=\u001b[39m storages\u001b[38;5;241m.\u001b[39mget_storage(storage)\n\u001b[0;32m   1264\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 1265\u001b[0m     study_id \u001b[38;5;241m=\u001b[39m \u001b[43mstorage\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate_new_study\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdirection_objects\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstudy_name\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1266\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m exceptions\u001b[38;5;241m.\u001b[39mDuplicatedStudyError:\n\u001b[0;32m   1267\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m load_if_exists:\n",
      "File \u001b[1;32mc:\\Users\\SiyuC\\.conda\\envs\\ml\\lib\\site-packages\\optuna\\storages\\journal\\_storage.py:155\u001b[0m, in \u001b[0;36mJournalStorage.create_new_study\u001b[1;34m(self, directions, study_name)\u001b[0m\n\u001b[0;32m    152\u001b[0m study_name \u001b[38;5;241m=\u001b[39m study_name \u001b[38;5;129;01mor\u001b[39;00m DEFAULT_STUDY_NAME_PREFIX \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mstr\u001b[39m(uuid\u001b[38;5;241m.\u001b[39muuid4())\n\u001b[0;32m    154\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_thread_lock:\n\u001b[1;32m--> 155\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_write_log\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    156\u001b[0m \u001b[43m        \u001b[49m\u001b[43mJournalOperation\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mCREATE_STUDY\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstudy_name\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstudy_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mdirections\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mdirections\u001b[49m\u001b[43m}\u001b[49m\n\u001b[0;32m    157\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    158\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sync_with_backend()\n\u001b[0;32m    160\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m frozen_study \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_replay_result\u001b[38;5;241m.\u001b[39mget_all_studies():\n",
      "File \u001b[1;32mc:\\Users\\SiyuC\\.conda\\envs\\ml\\lib\\site-packages\\optuna\\storages\\journal\\_storage.py:143\u001b[0m, in \u001b[0;36mJournalStorage._write_log\u001b[1;34m(self, op_code, extra_fields)\u001b[0m\n\u001b[0;32m    141\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_write_log\u001b[39m(\u001b[38;5;28mself\u001b[39m, op_code: \u001b[38;5;28mint\u001b[39m, extra_fields: Dict[\u001b[38;5;28mstr\u001b[39m, Any]) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    142\u001b[0m     worker_id \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_replay_result\u001b[38;5;241m.\u001b[39mworker_id\n\u001b[1;32m--> 143\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_backend\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mappend_logs\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mop_code\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_code\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mworker_id\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mworker_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mextra_fields\u001b[49m\u001b[43m}\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\SiyuC\\.conda\\envs\\ml\\lib\\site-packages\\optuna\\storages\\journal\\_file.py:101\u001b[0m, in \u001b[0;36mJournalFileBackend.append_logs\u001b[1;34m(self, logs)\u001b[0m\n\u001b[0;32m    100\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mappend_logs\u001b[39m(\u001b[38;5;28mself\u001b[39m, logs: \u001b[38;5;28mlist\u001b[39m[\u001b[38;5;28mdict\u001b[39m[\u001b[38;5;28mstr\u001b[39m, Any]]) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 101\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m get_lock_file(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock):\n\u001b[0;32m    102\u001b[0m         what_to_write \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    103\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin([json\u001b[38;5;241m.\u001b[39mdumps(log, separators\u001b[38;5;241m=\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m,\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m:\u001b[39m\u001b[38;5;124m\"\u001b[39m)) \u001b[38;5;28;01mfor\u001b[39;00m log \u001b[38;5;129;01min\u001b[39;00m logs]) \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    104\u001b[0m         )\n\u001b[0;32m    105\u001b[0m         \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_file_path, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mab\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n",
      "File \u001b[1;32mc:\\Users\\SiyuC\\.conda\\envs\\ml\\lib\\contextlib.py:135\u001b[0m, in \u001b[0;36m_GeneratorContextManager.__enter__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    133\u001b[0m \u001b[38;5;28;01mdel\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mkwds, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunc\n\u001b[0;32m    134\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 135\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mnext\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgen\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    136\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m:\n\u001b[0;32m    137\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgenerator didn\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt yield\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\SiyuC\\.conda\\envs\\ml\\lib\\site-packages\\optuna\\storages\\journal\\_file.py:228\u001b[0m, in \u001b[0;36mget_lock_file\u001b[1;34m(lock_obj)\u001b[0m\n\u001b[0;32m    226\u001b[0m \u001b[38;5;129m@contextmanager\u001b[39m\n\u001b[0;32m    227\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mget_lock_file\u001b[39m(lock_obj: BaseJournalFileLock) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Iterator[\u001b[38;5;28;01mNone\u001b[39;00m]:\n\u001b[1;32m--> 228\u001b[0m     \u001b[43mlock_obj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43macquire\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    229\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    230\u001b[0m         \u001b[38;5;28;01myield\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\SiyuC\\.conda\\envs\\ml\\lib\\site-packages\\optuna\\storages\\journal\\_file.py:154\u001b[0m, in \u001b[0;36mJournalFileSymlinkLock.acquire\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    152\u001b[0m         sleep_secs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mmin\u001b[39m(sleep_secs \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m    153\u001b[0m         \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[1;32m--> 154\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m err\n\u001b[0;32m    155\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m:\n\u001b[0;32m    156\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrelease()\n",
      "File \u001b[1;32mc:\\Users\\SiyuC\\.conda\\envs\\ml\\lib\\site-packages\\optuna\\storages\\journal\\_file.py:147\u001b[0m, in \u001b[0;36mJournalFileSymlinkLock.acquire\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    145\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m    146\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 147\u001b[0m         \u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msymlink\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_lock_target_file\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_lock_file\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    148\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m    149\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "\u001b[1;31mOSError\u001b[0m: [WinError 1314] A required privilege is not held by the client: 'd:\\\\git\\\\5LIL0-Intelligent-architectures\\\\assignments\\\\assignment2_partB\\\\mnist_nas\\\\journal.log' -> 'd:\\\\git\\\\5LIL0-Intelligent-architectures\\\\assignments\\\\assignment2_partB\\\\mnist_nas\\\\journal.log.lock'"
     ]
    }
   ],
   "source": [
    "# Set TensorFlow/Keras seed for reproducibility\n",
    "tf.keras.utils.set_random_seed(0)\n",
    "\n",
    "# Configure experiment \n",
    "exp_name = \"mnist_nas\"\n",
    "objectives = ['fp32_accuracy', 'num_params']\n",
    "directions= ['maximize', 'minimize']\n",
    "n_trials = 2\n",
    "epochs = 1\n",
    "lr = 0.001\n",
    "\n",
    "# create experiment directory\n",
    "exp_dir = os.path.join(os.getcwd(), exp_name)\n",
    "os.makedirs(exp_dir, exist_ok=True)\n",
    "\n",
    "# define search strategy and set seed for reproducibility\n",
    "sampler = TPESampler(seed=0)\n",
    "\n",
    "# Create optuna study for optimization (delete first if it already exists)\n",
    "try:\n",
    "    optuna.delete_study(study_name=exp_name,storage=JournalStorage(JournalFileBackend(os.path.join(exp_dir, \"journal.log\"))))\n",
    "except Exception:    \n",
    "    pass    \n",
    "study = optuna.create_study(\n",
    "    sampler=sampler,\n",
    "    study_name=exp_name,\n",
    "    storage=JournalStorage(JournalFileBackend(os.path.join(exp_dir, \"journal.log\"))),\n",
    "    # storage = \"sqlite:///mnist_nas.db\",\n",
    "    load_if_exists=True,\n",
    "    directions=directions,\n",
    ")\n",
    "\n",
    "# perform NAS\n",
    "study.optimize(NASNet(epochs=epochs, lr=lr, exp_dir=exp_dir, objectives=objectives), n_trials=n_trials)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "974b8ed1-3875-4821-b810-d179a1869c29",
   "metadata": {},
   "source": [
    "## 3. Visualizing the NAS Results\n",
    "\n",
    "Optuna has several built-in functions to visualize the results of an experiment, which we will explore below.\n",
    "\n",
    "### 3.1 Pareto Front\n",
    "\n",
    "Our optimization procedure provides various trade-offs between the two objectives of floating-point accuracy and number of parameters. As such, there is no single optimal solution and we instead use the notion of **Pareto optimality**. In a two-objective situation, a solution is said to be **Pareto optimal** if the only way to improve one of the objectives is to deteriorate the other objective. A solution that is not Pareto optimal is said to be **Pareto dominated** by some other solution. The set of Pareto optimal solutions forms the [**Pareto front**](https://en.wikipedia.org/wiki/Pareto_front) of a problem.\n",
    "\n",
    "Below, we use the ``plot_pareto_front`` function and we exclude all Pareto dominated solutions to only visualize the Pareto front. The plot is interactive, if you hover over any point you will details about the trial that produced this solution: ``values`` contains the values of our two objectives, ``params`` contains the hyperparameters corresponding to the solution, and ``user_attrs`` contains the additional information that we calculated for each trial (note that this also includes the two objectives for convenience)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57071d3d-089b-43f7-bab5-c5e273424b23",
   "metadata": {},
   "outputs": [],
   "source": [
    "optuna.visualization.plot_pareto_front(study,\n",
    "                                       targets=lambda t: (t.values[0]*100, t.values[1]), \n",
    "                                       target_names=['Accuracy (%)', 'Number of Parameters'], \n",
    "                                       include_dominated_trials=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e110cf8-34de-47d0-82fe-ff67b09b54e0",
   "metadata": {},
   "source": [
    "From this point on we want to include all trials in our plots, which we can do by omitting the ``include_dominated_trials`` parameter (its default value is ``True``). The Pareto optimal solutions are plotted with hues of red, while the Pareto dominated solutions are plotted with hues of blue. You can verify that, for any Pareto dominated solution, there exists a Pareto optimal solution that is better in at least one of our two optimization metrics, i.e., it has higher accuracy, or a smaller number of parameters, or both."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86314ecb-908a-4dea-a6ea-e8565674223a",
   "metadata": {},
   "outputs": [],
   "source": [
    "optuna.visualization.plot_pareto_front(study, \n",
    "                                       targets=lambda t: (t.values[0]*100, t.values[1]), \n",
    "                                       target_names=['Accuracy (%)', 'Number of Parameters'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e042cce-5dcd-4535-b268-ddb7f5e97b9a",
   "metadata": {},
   "source": [
    "We can also plot results stored in the ``user_attrs`` field. For example, below we plot the floating-point accuracy versus the model size of the quantized model in kB."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b3caa13-ca07-4ec8-bc68-d68ed7489897",
   "metadata": {},
   "outputs": [],
   "source": [
    "optuna.visualization.plot_pareto_front(study,\n",
    "                                       targets=lambda t: (t.values[0]*100, t.user_attrs['int8_model_size']), \n",
    "                                       target_names=['Accuracy (%)', 'Quantized Model Size (kB)'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ce1741d-e3de-40b1-93e5-e5453fb6ccdf",
   "metadata": {},
   "source": [
    "Finally, below we plot the latency of the model of each trial (``int8_latency``) when deployed on the Ethos U55 NPU (calculated by the ``_profile_model_latency`` function in the ``NASNet`` class using the Vela compiler) versus the quantized model size in kB. Note that, contrary to the title of the plot that is added automatically, in general this is no longer a Pareto front, since we are not plotting the two objectives (or a monotonic function of the objectives) against each other."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37cef049-865c-49a8-9128-c78420b54ef2",
   "metadata": {},
   "outputs": [],
   "source": [
    "optuna.visualization.plot_pareto_front(study,\n",
    "                                       targets=...), \n",
    "                                       target_names=['Latency (ms)', 'Quantized Model Size (kB)'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8708343a-1c3b-4c44-bb46-9f2fef7dd0dd",
   "metadata": {},
   "source": [
    "### 3.2 Per-Layer Performance Details\n",
    "\n",
    "You can find details about the performance and resource utilization of each layer of the neural network for trial number ``x`` in the folder ``mnist_nas/trial_x/vela_output/mnist_nas_full_int8_per-layer.csv``. For example, the column ``SRAM Usage`` shows how many bytes of the SRAM are used by each layer. Details for each column can be found [here](https://github.com/nxp-imx/ethos-u-vela/blob/lf-6.6.3_1.0.0/PERFORMANCE.md#vela-performance-estimation-per-layer)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f0584a7-6d99-4592-8690-7e360d039a9f",
   "metadata": {},
   "source": [
    "### 3.3 Hyperparameter Importance\n",
    "\n",
    "Optuna can tell us to what extent each hyperparameter influences the optimization of each objective (i.e., maximization or minimization, depending on the direction defined for each objective) and the user-defined parameters. This largely depends on the range that we have defined: if the range for some hyperparameter is very restrictive, it will become very important to increase/decrease it as much as possible. Nevertheless, this visualization gives an indication of the importance of each hyperparameter and, more importantly, can reveal the inherent conflicts and synergies between the optimization objectives.\n",
    "\n",
    "In the following three cells, we plot the importance of each hyperparameter for the accuracy, the number of parameters, and the quantized model latency, respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f397e21-ffe9-4bcb-abfa-ac0c15646c0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "optuna.visualization.plot_param_importances(study, target=lambda t: t.values[0]*100, target_name=\"Accuracy (%)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fb0b999-ea8e-422f-89b1-5d981c9265ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "optuna.visualization.plot_param_importances(study, target=lambda t: t.values[1], target_name=\"Number of Parameters\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1ba61ba-b730-40a3-b891-a0bee035d953",
   "metadata": {},
   "outputs": [],
   "source": [
    "optuna.visualization.plot_param_importances(study, target=lambda t: t.user_attrs['int8_latency'], target_name=\"Latency\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
