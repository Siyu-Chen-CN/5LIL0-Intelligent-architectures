{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "81f47b68-6931-4b5c-b542-f72a3a38716b",
   "metadata": {},
   "source": [
    "# Intelligent Architectures (5LIL0) Assignment 2 (version 0.1)\n",
    "\n",
    "#### **Authors:** [Alexios Balatsoukas-Stimming](mailto:a.k.balatsoukas.stimming@tue.nl) (TU/e), [Hiram Rayo Torres Rodriguez](mailto:hiram.rayotorresrodriguez@nxp.com) (NXP), [Willem Sanberg](mailto:willem.sanberg@nxp.com) (NXP)\n",
    "\n",
    "#### **License:** [CC BY-NC-SA 4.0](https://creativecommons.org/licenses/by-nc-sa/4.0/)\n",
    "\n",
    "## Part B: Neural Architecture Search\n",
    "\n",
    "In this part of the assignment, you will perform neural architecture search (NAS). As a NAS tool, you will use [Optuna](https://optuna.org/), which is a general framework for automated hyperparameter tuning and optimization. Contrary to previous assignments, the focus will be more on interpreting results rather than writing your own code. Also, we will use TensorFlow with the Keras front-end instead of PyTorch for the neural network operations. Finally, we will rely more on the confidence and independence you have developed through previous assignments (e.g., we may point you to online documentation for certain points rather than explaining all details).\n",
    "\n",
    "## 1. Setting up the NAS Experiment\n",
    "\n",
    "The class ``NASNet``, which is defined in the separate file ``NASNet.py``, contains various pre-implemented functions that are used to evaluate the performance of each NAS round, which is called a ``trial`` in Optuna terminology. In the table below is a list of the most important functions and their functionality:\n",
    "\n",
    "| Name | Functionality |\n",
    "| ------------- | ------------- |\n",
    "| ``__call__`` | Called when a class object is instantiated, performs training and calculates the optimization metrics |\n",
    "| ``_get_mnist_dataset`` | Loads and normalizes the MNIST dataset |\n",
    "| ``_quantize_model`` | Quantizes model using [LiteRT](https://ai.google.dev/edge/litert) using 8-bit full-integer quantization |\n",
    "| ``_evaluate_quantized_model`` | Calculates the accuracy of the quantized model |\n",
    "| ``_profile_model_latency`` | Calculates quantized model latency using the [Vela compiler](https://pypi.org/project/ethos-u-vela/) for an [ARM Ethos U55 NPU](https://armkeil.blob.core.windows.net/developer/Files/pdf/product-brief/arm-ethos-u55-product-brief.pdf) target |\n",
    "\n",
    "\n",
    "Let us now import the class and other packages that are required for this assignment (you can ignore any warnings/errors you see)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7f48b3fc-7afa-4d6d-8243-f087d8834a92",
   "metadata": {},
   "outputs": [],
   "source": [
    "from NASNet import NASNet\n",
    "import tensorflow as tf\n",
    "import logging\n",
    "import optuna\n",
    "from optuna.storages import JournalStorage\n",
    "from optuna.storages.journal import JournalFileBackend\n",
    "from optuna.samplers import TPESampler\n",
    "import os\n",
    "# os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"\"  # delete line to enable GPU-based training\n",
    "os.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = \"3\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8aef5cac-59f8-4312-a59b-b705f5418dad",
   "metadata": {},
   "source": [
    "Certain functionality was omitted from the NASNet class and we will implement it and add it to the class definition. First, a function is required to define the structure of the neural network to be optimized. We will implement a neural network for the MNIST dataset in Keras that looks as follows:\n",
    "\n",
    "Input (28x28 image, 1 channel) &rarr; Convolutional Layer (``num_filters`` filters, ``k_size``x``k_size`` filter size) &rarr; Batch Normalization Layer &rarr; ReLU activation &rarr; Dense Layer (``n_units`` neurons, ReLU activation) &rarr; Dense Layer (10 neurons, no activation) \n",
    "\n",
    "Note that ``num_filters``, ``k_size``, and ``n_units`` are parameters that will be optimized by Optuna. They can be accessed, for example for ``num_filters``, as ``self.trial_hp[\"num_filters\"]`` in the function below. Detailed documentation for Keras layers can be found [here](https://keras.io/api/layers/) and an explanation of the functional API to help you with the syntax can be found [here](https://keras.io/guides/functional_api/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "16e4de83-3409-4242-8dfc-50e74f8d38de",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _get_CNN(self, batch_size=256, training=True):\n",
    "    inputs = tf.keras.Input(shape=(28, 28, 1), batch_size=batch_size)\n",
    "\n",
    "    x = tf.keras.layers.Conv2D(filters=self.trial_hp[\"num_filters\"], \n",
    "                               kernel_size=self.trial_hp[\"k_size\"], \n",
    "                               padding=\"same\")(inputs)\n",
    "    x = tf.keras.layers.BatchNormalization()(x)\n",
    "    x = tf.keras.layers.ReLU()(x)\n",
    "    x = tf.keras.layers.Flatten()(x)\n",
    "    x = tf.keras.layers.Dense(units=self.trial_hp[\"n_units\"], activation=\"relu\")(x)\n",
    "\n",
    "    outputs = tf.keras.layers.Dense(10)(x)\n",
    "        \n",
    "    return tf.keras.Model(inputs=inputs,outputs=outputs)\n",
    "\n",
    "# Add function to class\n",
    "NASNet._get_CNN = _get_CNN"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac3d9d9b-546b-4587-8045-4388e0117358",
   "metadata": {},
   "source": [
    "Next, we need to define the search space for our three hyperparameters to guide the NAS procedure. This is done by simply calling (no return argument required) the ``trial.suggest_int`` function for each of the three named hyperparameters we used in the neural network definiton above (i.e., ``\"num_filters\"``, ``\"n_units\"`` and ``\"k_size\"``). You will find documentation and examples for this function [here](https://optuna.readthedocs.io/en/stable/reference/generated/optuna.trial.Trial.html#optuna.trial.Trial.suggest_int). The ranges for ``\"num_filters\"``, ``\"n_units\"`` and ``\"k_size\"`` should be [2,8], [4,16], and [3,9], respectively, with a step size of 2 for all hyperparameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "969911a1-0e2a-4674-8480-341435b92859",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _search_space_by_func(self, trial):\n",
    "        # search for kernel size, number of output features and neurons\n",
    "        self.num_filters = trial.suggest_int(\"num_filters\", 2, 8, step=2)\n",
    "        self.n_units = trial.suggest_int(\"n_units\", 4, 16, step=2)\n",
    "        self.k_size = trial.suggest_int(\"k_size\", 3, 9, step=2)\n",
    "        return trial.params\n",
    "\n",
    "# Add function to class\n",
    "NASNet._search_space_by_func = _search_space_by_func"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76963836-631f-472f-b7cb-4db85d9d94fa",
   "metadata": {},
   "source": [
    "## 2. Running the NAS Experiment\n",
    "\n",
    "Before running our NAS experiment, we need to define a name for it that will be used as a folder name for the results. More importantly, we need to define the objectives of the optimization, which in our case are the floating-point accuracy (``fp32_accuracy``) and the number of parameters in the neural network (``num_params``), which we want to maximize and minimize, respectively. These metrics are calculated in the ``__call__`` function of the ``NASNet`` class. We also define the number of training epochs (``epochs = 1`` to keep the runtime of the experiment reasonable) and the learning rate (``lr = 0.001``).\n",
    "\n",
    "Running this cell with the default values will take approximately 10 minutes. If you need to experiment to verify your code, you can set ``n_trials = 1`` temporarily to run the code in a few seconds. Don't forget to set it back to ``n_trials = 50`` before running the final experiment.\n",
    "\n",
    "If you are interested, you can read the outputs that are printed, but this is not necessary. We will visualize and interpret the results in the following section. If the output of the cell becomes too long making it difficult for you to work, you can right click on it and select \"Clear Cell Output\" after it has finished running."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8af64e01-dd10-4de5-870d-e547289fdb9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-24 23:46:24,914] A new study created in Journal with name: mnist_nas\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "224/235 [===========================>..] - ETA: 0s - loss: 0.4510 - accuracy: 0.8655"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[W 2025-03-24 23:46:27,838] Trial 0 failed with parameters: {'num_filters': 6, 'n_units': 14, 'k_size': 7} because of the following error: InvalidArgumentError().\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\Siyu Chen\\.conda\\envs\\program\\lib\\site-packages\\optuna\\study\\_optimize.py\", line 197, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "  File \"c:\\Users\\Siyu Chen\\git\\5LIL0-Intelligent-architectures\\assignments\\assignment2_partB\\NASNet.py\", line 45, in __call__\n",
      "    model.fit(ds_train, epochs=self.epochs, validation_data=ds_test)\n",
      "  File \"c:\\Users\\Siyu Chen\\.conda\\envs\\program\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 70, in error_handler\n",
      "    raise e.with_traceback(filtered_tb) from None\n",
      "  File \"c:\\Users\\Siyu Chen\\.conda\\envs\\program\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py\", line 54, in quick_execute\n",
      "    tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n",
      "tensorflow.python.framework.errors_impl.InvalidArgumentError: Graph execution error:\n",
      "\n",
      "Detected at node 'gradient_tape/sparse_categorical_crossentropy/SparseSoftmaxCrossEntropyWithLogits/mul' defined at (most recent call last):\n",
      "    File \"c:\\Users\\Siyu Chen\\.conda\\envs\\program\\lib\\runpy.py\", line 196, in _run_module_as_main\n",
      "      return _run_code(code, main_globals, None,\n",
      "    File \"c:\\Users\\Siyu Chen\\.conda\\envs\\program\\lib\\runpy.py\", line 86, in _run_code\n",
      "      exec(code, run_globals)\n",
      "    File \"c:\\Users\\Siyu Chen\\.conda\\envs\\program\\lib\\site-packages\\ipykernel_launcher.py\", line 18, in <module>\n",
      "      app.launch_new_instance()\n",
      "    File \"c:\\Users\\Siyu Chen\\.conda\\envs\\program\\lib\\site-packages\\traitlets\\config\\application.py\", line 1075, in launch_instance\n",
      "      app.start()\n",
      "    File \"c:\\Users\\Siyu Chen\\.conda\\envs\\program\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 739, in start\n",
      "      self.io_loop.start()\n",
      "    File \"c:\\Users\\Siyu Chen\\.conda\\envs\\program\\lib\\site-packages\\tornado\\platform\\asyncio.py\", line 205, in start\n",
      "      self.asyncio_loop.run_forever()\n",
      "    File \"c:\\Users\\Siyu Chen\\.conda\\envs\\program\\lib\\asyncio\\base_events.py\", line 603, in run_forever\n",
      "      self._run_once()\n",
      "    File \"c:\\Users\\Siyu Chen\\.conda\\envs\\program\\lib\\asyncio\\base_events.py\", line 1909, in _run_once\n",
      "      handle._run()\n",
      "    File \"c:\\Users\\Siyu Chen\\.conda\\envs\\program\\lib\\asyncio\\events.py\", line 80, in _run\n",
      "      self._context.run(self._callback, *self._args)\n",
      "    File \"c:\\Users\\Siyu Chen\\.conda\\envs\\program\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 545, in dispatch_queue\n",
      "      await self.process_one()\n",
      "    File \"c:\\Users\\Siyu Chen\\.conda\\envs\\program\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 534, in process_one\n",
      "      await dispatch(*args)\n",
      "    File \"c:\\Users\\Siyu Chen\\.conda\\envs\\program\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 437, in dispatch_shell\n",
      "      await result\n",
      "    File \"c:\\Users\\Siyu Chen\\.conda\\envs\\program\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 362, in execute_request\n",
      "      await super().execute_request(stream, ident, parent)\n",
      "    File \"c:\\Users\\Siyu Chen\\.conda\\envs\\program\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 778, in execute_request\n",
      "      reply_content = await reply_content\n",
      "    File \"c:\\Users\\Siyu Chen\\.conda\\envs\\program\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 449, in do_execute\n",
      "      res = shell.run_cell(\n",
      "    File \"c:\\Users\\Siyu Chen\\.conda\\envs\\program\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 549, in run_cell\n",
      "      return super().run_cell(*args, **kwargs)\n",
      "    File \"c:\\Users\\Siyu Chen\\.conda\\envs\\program\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3075, in run_cell\n",
      "      result = self._run_cell(\n",
      "    File \"c:\\Users\\Siyu Chen\\.conda\\envs\\program\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3130, in _run_cell\n",
      "      result = runner(coro)\n",
      "    File \"c:\\Users\\Siyu Chen\\.conda\\envs\\program\\lib\\site-packages\\IPython\\core\\async_helpers.py\", line 128, in _pseudo_sync_runner\n",
      "      coro.send(None)\n",
      "    File \"c:\\Users\\Siyu Chen\\.conda\\envs\\program\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3334, in run_cell_async\n",
      "      has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n",
      "    File \"c:\\Users\\Siyu Chen\\.conda\\envs\\program\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3517, in run_ast_nodes\n",
      "      if await self.run_code(code, result, async_=asy):\n",
      "    File \"c:\\Users\\Siyu Chen\\.conda\\envs\\program\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3577, in run_code\n",
      "      exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "    File \"C:\\Users\\Siyu Chen\\AppData\\Local\\Temp\\ipykernel_13788\\3529270118.py\", line 34, in <module>\n",
      "      study.optimize(NASNet(epochs=epochs, lr=lr, exp_dir=exp_dir, objectives=objectives), n_trials=n_trials)\n",
      "    File \"c:\\Users\\Siyu Chen\\.conda\\envs\\program\\lib\\site-packages\\optuna\\study\\study.py\", line 475, in optimize\n",
      "      _optimize(\n",
      "    File \"c:\\Users\\Siyu Chen\\.conda\\envs\\program\\lib\\site-packages\\optuna\\study\\_optimize.py\", line 63, in _optimize\n",
      "      _optimize_sequential(\n",
      "    File \"c:\\Users\\Siyu Chen\\.conda\\envs\\program\\lib\\site-packages\\optuna\\study\\_optimize.py\", line 160, in _optimize_sequential\n",
      "      frozen_trial = _run_trial(study, func, catch)\n",
      "    File \"c:\\Users\\Siyu Chen\\.conda\\envs\\program\\lib\\site-packages\\optuna\\study\\_optimize.py\", line 197, in _run_trial\n",
      "      value_or_values = func(trial)\n",
      "    File \"c:\\Users\\Siyu Chen\\git\\5LIL0-Intelligent-architectures\\assignments\\assignment2_partB\\NASNet.py\", line 45, in __call__\n",
      "      model.fit(ds_train, epochs=self.epochs, validation_data=ds_test)\n",
      "    File \"c:\\Users\\Siyu Chen\\.conda\\envs\\program\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 65, in error_handler\n",
      "      return fn(*args, **kwargs)\n",
      "    File \"c:\\Users\\Siyu Chen\\.conda\\envs\\program\\lib\\site-packages\\keras\\engine\\training.py\", line 1564, in fit\n",
      "      tmp_logs = self.train_function(iterator)\n",
      "    File \"c:\\Users\\Siyu Chen\\.conda\\envs\\program\\lib\\site-packages\\keras\\engine\\training.py\", line 1160, in train_function\n",
      "      return step_function(self, iterator)\n",
      "    File \"c:\\Users\\Siyu Chen\\.conda\\envs\\program\\lib\\site-packages\\keras\\engine\\training.py\", line 1146, in step_function\n",
      "      outputs = model.distribute_strategy.run(run_step, args=(data,))\n",
      "    File \"c:\\Users\\Siyu Chen\\.conda\\envs\\program\\lib\\site-packages\\keras\\engine\\training.py\", line 1135, in run_step\n",
      "      outputs = model.train_step(data)\n",
      "    File \"c:\\Users\\Siyu Chen\\.conda\\envs\\program\\lib\\site-packages\\keras\\engine\\training.py\", line 997, in train_step\n",
      "      self.optimizer.minimize(loss, self.trainable_variables, tape=tape)\n",
      "    File \"c:\\Users\\Siyu Chen\\.conda\\envs\\program\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\optimizer_v2.py\", line 576, in minimize\n",
      "      grads_and_vars = self._compute_gradients(\n",
      "    File \"c:\\Users\\Siyu Chen\\.conda\\envs\\program\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\optimizer_v2.py\", line 634, in _compute_gradients\n",
      "      grads_and_vars = self._get_gradients(\n",
      "    File \"c:\\Users\\Siyu Chen\\.conda\\envs\\program\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\optimizer_v2.py\", line 510, in _get_gradients\n",
      "      grads = tape.gradient(loss, var_list, grad_loss)\n",
      "Node: 'gradient_tape/sparse_categorical_crossentropy/SparseSoftmaxCrossEntropyWithLogits/mul'\n",
      "required broadcastable shapes\n",
      "\t [[{{node gradient_tape/sparse_categorical_crossentropy/SparseSoftmaxCrossEntropyWithLogits/mul}}]] [Op:__inference_train_function_2909]\n",
      "[W 2025-03-24 23:46:27,838] Trial 0 failed with value None.\n"
     ]
    },
    {
     "ename": "InvalidArgumentError",
     "evalue": "Graph execution error:\n\nDetected at node 'gradient_tape/sparse_categorical_crossentropy/SparseSoftmaxCrossEntropyWithLogits/mul' defined at (most recent call last):\n    File \"c:\\Users\\Siyu Chen\\.conda\\envs\\program\\lib\\runpy.py\", line 196, in _run_module_as_main\n      return _run_code(code, main_globals, None,\n    File \"c:\\Users\\Siyu Chen\\.conda\\envs\\program\\lib\\runpy.py\", line 86, in _run_code\n      exec(code, run_globals)\n    File \"c:\\Users\\Siyu Chen\\.conda\\envs\\program\\lib\\site-packages\\ipykernel_launcher.py\", line 18, in <module>\n      app.launch_new_instance()\n    File \"c:\\Users\\Siyu Chen\\.conda\\envs\\program\\lib\\site-packages\\traitlets\\config\\application.py\", line 1075, in launch_instance\n      app.start()\n    File \"c:\\Users\\Siyu Chen\\.conda\\envs\\program\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 739, in start\n      self.io_loop.start()\n    File \"c:\\Users\\Siyu Chen\\.conda\\envs\\program\\lib\\site-packages\\tornado\\platform\\asyncio.py\", line 205, in start\n      self.asyncio_loop.run_forever()\n    File \"c:\\Users\\Siyu Chen\\.conda\\envs\\program\\lib\\asyncio\\base_events.py\", line 603, in run_forever\n      self._run_once()\n    File \"c:\\Users\\Siyu Chen\\.conda\\envs\\program\\lib\\asyncio\\base_events.py\", line 1909, in _run_once\n      handle._run()\n    File \"c:\\Users\\Siyu Chen\\.conda\\envs\\program\\lib\\asyncio\\events.py\", line 80, in _run\n      self._context.run(self._callback, *self._args)\n    File \"c:\\Users\\Siyu Chen\\.conda\\envs\\program\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 545, in dispatch_queue\n      await self.process_one()\n    File \"c:\\Users\\Siyu Chen\\.conda\\envs\\program\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 534, in process_one\n      await dispatch(*args)\n    File \"c:\\Users\\Siyu Chen\\.conda\\envs\\program\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 437, in dispatch_shell\n      await result\n    File \"c:\\Users\\Siyu Chen\\.conda\\envs\\program\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 362, in execute_request\n      await super().execute_request(stream, ident, parent)\n    File \"c:\\Users\\Siyu Chen\\.conda\\envs\\program\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 778, in execute_request\n      reply_content = await reply_content\n    File \"c:\\Users\\Siyu Chen\\.conda\\envs\\program\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 449, in do_execute\n      res = shell.run_cell(\n    File \"c:\\Users\\Siyu Chen\\.conda\\envs\\program\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 549, in run_cell\n      return super().run_cell(*args, **kwargs)\n    File \"c:\\Users\\Siyu Chen\\.conda\\envs\\program\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3075, in run_cell\n      result = self._run_cell(\n    File \"c:\\Users\\Siyu Chen\\.conda\\envs\\program\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3130, in _run_cell\n      result = runner(coro)\n    File \"c:\\Users\\Siyu Chen\\.conda\\envs\\program\\lib\\site-packages\\IPython\\core\\async_helpers.py\", line 128, in _pseudo_sync_runner\n      coro.send(None)\n    File \"c:\\Users\\Siyu Chen\\.conda\\envs\\program\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3334, in run_cell_async\n      has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n    File \"c:\\Users\\Siyu Chen\\.conda\\envs\\program\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3517, in run_ast_nodes\n      if await self.run_code(code, result, async_=asy):\n    File \"c:\\Users\\Siyu Chen\\.conda\\envs\\program\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3577, in run_code\n      exec(code_obj, self.user_global_ns, self.user_ns)\n    File \"C:\\Users\\Siyu Chen\\AppData\\Local\\Temp\\ipykernel_13788\\3529270118.py\", line 34, in <module>\n      study.optimize(NASNet(epochs=epochs, lr=lr, exp_dir=exp_dir, objectives=objectives), n_trials=n_trials)\n    File \"c:\\Users\\Siyu Chen\\.conda\\envs\\program\\lib\\site-packages\\optuna\\study\\study.py\", line 475, in optimize\n      _optimize(\n    File \"c:\\Users\\Siyu Chen\\.conda\\envs\\program\\lib\\site-packages\\optuna\\study\\_optimize.py\", line 63, in _optimize\n      _optimize_sequential(\n    File \"c:\\Users\\Siyu Chen\\.conda\\envs\\program\\lib\\site-packages\\optuna\\study\\_optimize.py\", line 160, in _optimize_sequential\n      frozen_trial = _run_trial(study, func, catch)\n    File \"c:\\Users\\Siyu Chen\\.conda\\envs\\program\\lib\\site-packages\\optuna\\study\\_optimize.py\", line 197, in _run_trial\n      value_or_values = func(trial)\n    File \"c:\\Users\\Siyu Chen\\git\\5LIL0-Intelligent-architectures\\assignments\\assignment2_partB\\NASNet.py\", line 45, in __call__\n      model.fit(ds_train, epochs=self.epochs, validation_data=ds_test)\n    File \"c:\\Users\\Siyu Chen\\.conda\\envs\\program\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"c:\\Users\\Siyu Chen\\.conda\\envs\\program\\lib\\site-packages\\keras\\engine\\training.py\", line 1564, in fit\n      tmp_logs = self.train_function(iterator)\n    File \"c:\\Users\\Siyu Chen\\.conda\\envs\\program\\lib\\site-packages\\keras\\engine\\training.py\", line 1160, in train_function\n      return step_function(self, iterator)\n    File \"c:\\Users\\Siyu Chen\\.conda\\envs\\program\\lib\\site-packages\\keras\\engine\\training.py\", line 1146, in step_function\n      outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"c:\\Users\\Siyu Chen\\.conda\\envs\\program\\lib\\site-packages\\keras\\engine\\training.py\", line 1135, in run_step\n      outputs = model.train_step(data)\n    File \"c:\\Users\\Siyu Chen\\.conda\\envs\\program\\lib\\site-packages\\keras\\engine\\training.py\", line 997, in train_step\n      self.optimizer.minimize(loss, self.trainable_variables, tape=tape)\n    File \"c:\\Users\\Siyu Chen\\.conda\\envs\\program\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\optimizer_v2.py\", line 576, in minimize\n      grads_and_vars = self._compute_gradients(\n    File \"c:\\Users\\Siyu Chen\\.conda\\envs\\program\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\optimizer_v2.py\", line 634, in _compute_gradients\n      grads_and_vars = self._get_gradients(\n    File \"c:\\Users\\Siyu Chen\\.conda\\envs\\program\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\optimizer_v2.py\", line 510, in _get_gradients\n      grads = tape.gradient(loss, var_list, grad_loss)\nNode: 'gradient_tape/sparse_categorical_crossentropy/SparseSoftmaxCrossEntropyWithLogits/mul'\nrequired broadcastable shapes\n\t [[{{node gradient_tape/sparse_categorical_crossentropy/SparseSoftmaxCrossEntropyWithLogits/mul}}]] [Op:__inference_train_function_2909]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[8], line 34\u001b[0m\n\u001b[0;32m     24\u001b[0m study \u001b[38;5;241m=\u001b[39m optuna\u001b[38;5;241m.\u001b[39mcreate_study(\n\u001b[0;32m     25\u001b[0m     sampler\u001b[38;5;241m=\u001b[39msampler,\n\u001b[0;32m     26\u001b[0m     study_name\u001b[38;5;241m=\u001b[39mexp_name,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     30\u001b[0m     directions\u001b[38;5;241m=\u001b[39mdirections,\n\u001b[0;32m     31\u001b[0m )\n\u001b[0;32m     33\u001b[0m \u001b[38;5;66;03m# perform NAS\u001b[39;00m\n\u001b[1;32m---> 34\u001b[0m \u001b[43mstudy\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptimize\u001b[49m\u001b[43m(\u001b[49m\u001b[43mNASNet\u001b[49m\u001b[43m(\u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mepochs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexp_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mexp_dir\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mobjectives\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mobjectives\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_trials\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Siyu Chen\\.conda\\envs\\program\\lib\\site-packages\\optuna\\study\\study.py:475\u001b[0m, in \u001b[0;36mStudy.optimize\u001b[1;34m(self, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[0;32m    373\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21moptimize\u001b[39m(\n\u001b[0;32m    374\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    375\u001b[0m     func: ObjectiveFuncType,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    382\u001b[0m     show_progress_bar: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m    383\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    384\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Optimize an objective function.\u001b[39;00m\n\u001b[0;32m    385\u001b[0m \n\u001b[0;32m    386\u001b[0m \u001b[38;5;124;03m    Optimization is done by choosing a suitable set of hyperparameter values from a given\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    473\u001b[0m \u001b[38;5;124;03m            If nested invocation of this method occurs.\u001b[39;00m\n\u001b[0;32m    474\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 475\u001b[0m     \u001b[43m_optimize\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    476\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstudy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    477\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfunc\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    478\u001b[0m \u001b[43m        \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_trials\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    479\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    480\u001b[0m \u001b[43m        \u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_jobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    481\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcatch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mtuple\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43misinstance\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mIterable\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    482\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    483\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgc_after_trial\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgc_after_trial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    484\u001b[0m \u001b[43m        \u001b[49m\u001b[43mshow_progress_bar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mshow_progress_bar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    485\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Siyu Chen\\.conda\\envs\\program\\lib\\site-packages\\optuna\\study\\_optimize.py:63\u001b[0m, in \u001b[0;36m_optimize\u001b[1;34m(study, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[0;32m     61\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     62\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m n_jobs \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m---> 63\u001b[0m         \u001b[43m_optimize_sequential\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     64\u001b[0m \u001b[43m            \u001b[49m\u001b[43mstudy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     65\u001b[0m \u001b[43m            \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     66\u001b[0m \u001b[43m            \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     67\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     68\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     69\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     70\u001b[0m \u001b[43m            \u001b[49m\u001b[43mgc_after_trial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     71\u001b[0m \u001b[43m            \u001b[49m\u001b[43mreseed_sampler_rng\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m     72\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtime_start\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m     73\u001b[0m \u001b[43m            \u001b[49m\u001b[43mprogress_bar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprogress_bar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     74\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     75\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     76\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m n_jobs \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m:\n",
      "File \u001b[1;32mc:\\Users\\Siyu Chen\\.conda\\envs\\program\\lib\\site-packages\\optuna\\study\\_optimize.py:160\u001b[0m, in \u001b[0;36m_optimize_sequential\u001b[1;34m(study, func, n_trials, timeout, catch, callbacks, gc_after_trial, reseed_sampler_rng, time_start, progress_bar)\u001b[0m\n\u001b[0;32m    157\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[0;32m    159\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 160\u001b[0m     frozen_trial \u001b[38;5;241m=\u001b[39m \u001b[43m_run_trial\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstudy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    161\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    162\u001b[0m     \u001b[38;5;66;03m# The following line mitigates memory problems that can be occurred in some\u001b[39;00m\n\u001b[0;32m    163\u001b[0m     \u001b[38;5;66;03m# environments (e.g., services that use computing containers such as GitHub Actions).\u001b[39;00m\n\u001b[0;32m    164\u001b[0m     \u001b[38;5;66;03m# Please refer to the following PR for further details:\u001b[39;00m\n\u001b[0;32m    165\u001b[0m     \u001b[38;5;66;03m# https://github.com/optuna/optuna/pull/325.\u001b[39;00m\n\u001b[0;32m    166\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m gc_after_trial:\n",
      "File \u001b[1;32mc:\\Users\\Siyu Chen\\.conda\\envs\\program\\lib\\site-packages\\optuna\\study\\_optimize.py:248\u001b[0m, in \u001b[0;36m_run_trial\u001b[1;34m(study, func, catch)\u001b[0m\n\u001b[0;32m    241\u001b[0m         \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mShould not reach.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    243\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[0;32m    244\u001b[0m     frozen_trial\u001b[38;5;241m.\u001b[39mstate \u001b[38;5;241m==\u001b[39m TrialState\u001b[38;5;241m.\u001b[39mFAIL\n\u001b[0;32m    245\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m func_err \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    246\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(func_err, catch)\n\u001b[0;32m    247\u001b[0m ):\n\u001b[1;32m--> 248\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m func_err\n\u001b[0;32m    249\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m frozen_trial\n",
      "File \u001b[1;32mc:\\Users\\Siyu Chen\\.conda\\envs\\program\\lib\\site-packages\\optuna\\study\\_optimize.py:197\u001b[0m, in \u001b[0;36m_run_trial\u001b[1;34m(study, func, catch)\u001b[0m\n\u001b[0;32m    195\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m get_heartbeat_thread(trial\u001b[38;5;241m.\u001b[39m_trial_id, study\u001b[38;5;241m.\u001b[39m_storage):\n\u001b[0;32m    196\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 197\u001b[0m         value_or_values \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    198\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m exceptions\u001b[38;5;241m.\u001b[39mTrialPruned \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    199\u001b[0m         \u001b[38;5;66;03m# TODO(mamu): Handle multi-objective cases.\u001b[39;00m\n\u001b[0;32m    200\u001b[0m         state \u001b[38;5;241m=\u001b[39m TrialState\u001b[38;5;241m.\u001b[39mPRUNED\n",
      "File \u001b[1;32mc:\\Users\\Siyu Chen\\git\\5LIL0-Intelligent-architectures\\assignments\\assignment2_partB\\NASNet.py:45\u001b[0m, in \u001b[0;36mNASNet.__call__\u001b[1;34m(self, trial)\u001b[0m\n\u001b[0;32m     42\u001b[0m ds_train, ds_test \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_mnist_dataset()\n\u001b[0;32m     44\u001b[0m \u001b[38;5;66;03m# train model\u001b[39;00m\n\u001b[1;32m---> 45\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mds_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mepochs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mds_test\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     47\u001b[0m \u001b[38;5;66;03m# save model on trial directory\u001b[39;00m\n\u001b[0;32m     48\u001b[0m model\u001b[38;5;241m.\u001b[39msave(os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mwork_dir, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmnist_trained_model.keras\u001b[39m\u001b[38;5;124m\"\u001b[39m))\n",
      "File \u001b[1;32mc:\\Users\\Siyu Chen\\.conda\\envs\\program\\lib\\site-packages\\keras\\utils\\traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m     68\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m     69\u001b[0m     \u001b[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m---> 70\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     71\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m     72\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32mc:\\Users\\Siyu Chen\\.conda\\envs\\program\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py:54\u001b[0m, in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     52\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     53\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[1;32m---> 54\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m pywrap_tfe\u001b[38;5;241m.\u001b[39mTFE_Py_Execute(ctx\u001b[38;5;241m.\u001b[39m_handle, device_name, op_name,\n\u001b[0;32m     55\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[0;32m     56\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     57\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[1;31mInvalidArgumentError\u001b[0m: Graph execution error:\n\nDetected at node 'gradient_tape/sparse_categorical_crossentropy/SparseSoftmaxCrossEntropyWithLogits/mul' defined at (most recent call last):\n    File \"c:\\Users\\Siyu Chen\\.conda\\envs\\program\\lib\\runpy.py\", line 196, in _run_module_as_main\n      return _run_code(code, main_globals, None,\n    File \"c:\\Users\\Siyu Chen\\.conda\\envs\\program\\lib\\runpy.py\", line 86, in _run_code\n      exec(code, run_globals)\n    File \"c:\\Users\\Siyu Chen\\.conda\\envs\\program\\lib\\site-packages\\ipykernel_launcher.py\", line 18, in <module>\n      app.launch_new_instance()\n    File \"c:\\Users\\Siyu Chen\\.conda\\envs\\program\\lib\\site-packages\\traitlets\\config\\application.py\", line 1075, in launch_instance\n      app.start()\n    File \"c:\\Users\\Siyu Chen\\.conda\\envs\\program\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 739, in start\n      self.io_loop.start()\n    File \"c:\\Users\\Siyu Chen\\.conda\\envs\\program\\lib\\site-packages\\tornado\\platform\\asyncio.py\", line 205, in start\n      self.asyncio_loop.run_forever()\n    File \"c:\\Users\\Siyu Chen\\.conda\\envs\\program\\lib\\asyncio\\base_events.py\", line 603, in run_forever\n      self._run_once()\n    File \"c:\\Users\\Siyu Chen\\.conda\\envs\\program\\lib\\asyncio\\base_events.py\", line 1909, in _run_once\n      handle._run()\n    File \"c:\\Users\\Siyu Chen\\.conda\\envs\\program\\lib\\asyncio\\events.py\", line 80, in _run\n      self._context.run(self._callback, *self._args)\n    File \"c:\\Users\\Siyu Chen\\.conda\\envs\\program\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 545, in dispatch_queue\n      await self.process_one()\n    File \"c:\\Users\\Siyu Chen\\.conda\\envs\\program\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 534, in process_one\n      await dispatch(*args)\n    File \"c:\\Users\\Siyu Chen\\.conda\\envs\\program\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 437, in dispatch_shell\n      await result\n    File \"c:\\Users\\Siyu Chen\\.conda\\envs\\program\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 362, in execute_request\n      await super().execute_request(stream, ident, parent)\n    File \"c:\\Users\\Siyu Chen\\.conda\\envs\\program\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 778, in execute_request\n      reply_content = await reply_content\n    File \"c:\\Users\\Siyu Chen\\.conda\\envs\\program\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 449, in do_execute\n      res = shell.run_cell(\n    File \"c:\\Users\\Siyu Chen\\.conda\\envs\\program\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 549, in run_cell\n      return super().run_cell(*args, **kwargs)\n    File \"c:\\Users\\Siyu Chen\\.conda\\envs\\program\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3075, in run_cell\n      result = self._run_cell(\n    File \"c:\\Users\\Siyu Chen\\.conda\\envs\\program\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3130, in _run_cell\n      result = runner(coro)\n    File \"c:\\Users\\Siyu Chen\\.conda\\envs\\program\\lib\\site-packages\\IPython\\core\\async_helpers.py\", line 128, in _pseudo_sync_runner\n      coro.send(None)\n    File \"c:\\Users\\Siyu Chen\\.conda\\envs\\program\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3334, in run_cell_async\n      has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n    File \"c:\\Users\\Siyu Chen\\.conda\\envs\\program\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3517, in run_ast_nodes\n      if await self.run_code(code, result, async_=asy):\n    File \"c:\\Users\\Siyu Chen\\.conda\\envs\\program\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3577, in run_code\n      exec(code_obj, self.user_global_ns, self.user_ns)\n    File \"C:\\Users\\Siyu Chen\\AppData\\Local\\Temp\\ipykernel_13788\\3529270118.py\", line 34, in <module>\n      study.optimize(NASNet(epochs=epochs, lr=lr, exp_dir=exp_dir, objectives=objectives), n_trials=n_trials)\n    File \"c:\\Users\\Siyu Chen\\.conda\\envs\\program\\lib\\site-packages\\optuna\\study\\study.py\", line 475, in optimize\n      _optimize(\n    File \"c:\\Users\\Siyu Chen\\.conda\\envs\\program\\lib\\site-packages\\optuna\\study\\_optimize.py\", line 63, in _optimize\n      _optimize_sequential(\n    File \"c:\\Users\\Siyu Chen\\.conda\\envs\\program\\lib\\site-packages\\optuna\\study\\_optimize.py\", line 160, in _optimize_sequential\n      frozen_trial = _run_trial(study, func, catch)\n    File \"c:\\Users\\Siyu Chen\\.conda\\envs\\program\\lib\\site-packages\\optuna\\study\\_optimize.py\", line 197, in _run_trial\n      value_or_values = func(trial)\n    File \"c:\\Users\\Siyu Chen\\git\\5LIL0-Intelligent-architectures\\assignments\\assignment2_partB\\NASNet.py\", line 45, in __call__\n      model.fit(ds_train, epochs=self.epochs, validation_data=ds_test)\n    File \"c:\\Users\\Siyu Chen\\.conda\\envs\\program\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"c:\\Users\\Siyu Chen\\.conda\\envs\\program\\lib\\site-packages\\keras\\engine\\training.py\", line 1564, in fit\n      tmp_logs = self.train_function(iterator)\n    File \"c:\\Users\\Siyu Chen\\.conda\\envs\\program\\lib\\site-packages\\keras\\engine\\training.py\", line 1160, in train_function\n      return step_function(self, iterator)\n    File \"c:\\Users\\Siyu Chen\\.conda\\envs\\program\\lib\\site-packages\\keras\\engine\\training.py\", line 1146, in step_function\n      outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"c:\\Users\\Siyu Chen\\.conda\\envs\\program\\lib\\site-packages\\keras\\engine\\training.py\", line 1135, in run_step\n      outputs = model.train_step(data)\n    File \"c:\\Users\\Siyu Chen\\.conda\\envs\\program\\lib\\site-packages\\keras\\engine\\training.py\", line 997, in train_step\n      self.optimizer.minimize(loss, self.trainable_variables, tape=tape)\n    File \"c:\\Users\\Siyu Chen\\.conda\\envs\\program\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\optimizer_v2.py\", line 576, in minimize\n      grads_and_vars = self._compute_gradients(\n    File \"c:\\Users\\Siyu Chen\\.conda\\envs\\program\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\optimizer_v2.py\", line 634, in _compute_gradients\n      grads_and_vars = self._get_gradients(\n    File \"c:\\Users\\Siyu Chen\\.conda\\envs\\program\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\optimizer_v2.py\", line 510, in _get_gradients\n      grads = tape.gradient(loss, var_list, grad_loss)\nNode: 'gradient_tape/sparse_categorical_crossentropy/SparseSoftmaxCrossEntropyWithLogits/mul'\nrequired broadcastable shapes\n\t [[{{node gradient_tape/sparse_categorical_crossentropy/SparseSoftmaxCrossEntropyWithLogits/mul}}]] [Op:__inference_train_function_2909]"
     ]
    }
   ],
   "source": [
    "# Set TensorFlow/Keras seed for reproducibility\n",
    "tf.keras.utils.set_random_seed(0)\n",
    "\n",
    "# Configure experiment \n",
    "exp_name = \"mnist_nas\"\n",
    "objectives = ['fp32_accuracy', 'num_params']\n",
    "directions= ['maximize', 'minimize']\n",
    "n_trials = 1\n",
    "epochs = 1\n",
    "lr = 0.001\n",
    "\n",
    "# create experiment directory\n",
    "exp_dir = os.path.join(os.getcwd(), exp_name)\n",
    "os.makedirs(exp_dir, exist_ok=True)\n",
    "\n",
    "# define search strategy and set seed for reproducibility\n",
    "sampler = TPESampler(seed=0)\n",
    "\n",
    "# Create optuna study for optimization (delete first if it already exists)\n",
    "try:\n",
    "    optuna.delete_study(study_name=exp_name,storage=JournalStorage(JournalFileBackend(os.path.join(exp_dir, \"journal.log\"))))\n",
    "except Exception:    \n",
    "    pass    \n",
    "study = optuna.create_study(\n",
    "    sampler=sampler,\n",
    "    study_name=exp_name,\n",
    "    storage=JournalStorage(JournalFileBackend(os.path.join(exp_dir, \"journal.log\"))),\n",
    "    # storage = \"sqlite:///mnist_nas.db\",\n",
    "    load_if_exists=True,\n",
    "    directions=directions,\n",
    ")\n",
    "\n",
    "# perform NAS\n",
    "study.optimize(NASNet(epochs=epochs, lr=lr, exp_dir=exp_dir, objectives=objectives), n_trials=n_trials)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "974b8ed1-3875-4821-b810-d179a1869c29",
   "metadata": {},
   "source": [
    "## 3. Visualizing the NAS Results\n",
    "\n",
    "Optuna has several built-in functions to visualize the results of an experiment, which we will explore below.\n",
    "\n",
    "### 3.1 Pareto Front\n",
    "\n",
    "Our optimization procedure provides various trade-offs between the two objectives of floating-point accuracy and number of parameters. As such, there is no single optimal solution and we instead use the notion of **Pareto optimality**. In a two-objective situation, a solution is said to be **Pareto optimal** if the only way to improve one of the objectives is to deteriorate the other objective. A solution that is not Pareto optimal is said to be **Pareto dominated** by some other solution. The set of Pareto optimal solutions forms the [**Pareto front**](https://en.wikipedia.org/wiki/Pareto_front) of a problem.\n",
    "\n",
    "Below, we use the ``plot_pareto_front`` function and we exclude all Pareto dominated solutions to only visualize the Pareto front. The plot is interactive, if you hover over any point you will details about the trial that produced this solution: ``values`` contains the values of our two objectives, ``params`` contains the hyperparameters corresponding to the solution, and ``user_attrs`` contains the additional information that we calculated for each trial (note that this also includes the two objectives for convenience)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57071d3d-089b-43f7-bab5-c5e273424b23",
   "metadata": {},
   "outputs": [],
   "source": [
    "optuna.visualization.plot_pareto_front(study,\n",
    "                                       targets=lambda t: (t.values[0]*100, t.values[1]), \n",
    "                                       target_names=['Accuracy (%)', 'Number of Parameters'], \n",
    "                                       include_dominated_trials=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e110cf8-34de-47d0-82fe-ff67b09b54e0",
   "metadata": {},
   "source": [
    "From this point on we want to include all trials in our plots, which we can do by omitting the ``include_dominated_trials`` parameter (its default value is ``True``). The Pareto optimal solutions are plotted with hues of red, while the Pareto dominated solutions are plotted with hues of blue. You can verify that, for any Pareto dominated solution, there exists a Pareto optimal solution that is better in at least one of our two optimization metrics, i.e., it has higher accuracy, or a smaller number of parameters, or both."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86314ecb-908a-4dea-a6ea-e8565674223a",
   "metadata": {},
   "outputs": [],
   "source": [
    "optuna.visualization.plot_pareto_front(study, \n",
    "                                       targets=lambda t: (t.values[0]*100, t.values[1]), \n",
    "                                       target_names=['Accuracy (%)', 'Number of Parameters'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e042cce-5dcd-4535-b268-ddb7f5e97b9a",
   "metadata": {},
   "source": [
    "We can also plot results stored in the ``user_attrs`` field. For example, below we plot the floating-point accuracy versus the model size of the quantized model in kB."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b3caa13-ca07-4ec8-bc68-d68ed7489897",
   "metadata": {},
   "outputs": [],
   "source": [
    "optuna.visualization.plot_pareto_front(study,\n",
    "                                       targets=lambda t: (t.values[0]*100, t.user_attrs['int8_model_size']), \n",
    "                                       target_names=['Accuracy (%)', 'Quantized Model Size (kB)'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ce1741d-e3de-40b1-93e5-e5453fb6ccdf",
   "metadata": {},
   "source": [
    "Finally, below we plot the latency of the model of each trial (``int8_latency``) when deployed on the Ethos U55 NPU (calculated by the ``_profile_model_latency`` function in the ``NASNet`` class using the Vela compiler) versus the quantized model size in kB. Note that, contrary to the title of the plot that is added automatically, in general this is no longer a Pareto front, since we are not plotting the two objectives (or a monotonic function of the objectives) against each other."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37cef049-865c-49a8-9128-c78420b54ef2",
   "metadata": {},
   "outputs": [],
   "source": [
    "optuna.visualization.plot_pareto_front(study,\n",
    "                                       targets=...), \n",
    "                                       target_names=['Latency (ms)', 'Quantized Model Size (kB)'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8708343a-1c3b-4c44-bb46-9f2fef7dd0dd",
   "metadata": {},
   "source": [
    "### 3.2 Per-Layer Performance Details\n",
    "\n",
    "You can find details about the performance and resource utilization of each layer of the neural network for trial number ``x`` in the folder ``mnist_nas/trial_x/vela_output/mnist_nas_full_int8_per-layer.csv``. For example, the column ``SRAM Usage`` shows how many bytes of the SRAM are used by each layer. Details for each column can be found [here](https://github.com/nxp-imx/ethos-u-vela/blob/lf-6.6.3_1.0.0/PERFORMANCE.md#vela-performance-estimation-per-layer)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f0584a7-6d99-4592-8690-7e360d039a9f",
   "metadata": {},
   "source": [
    "### 3.3 Hyperparameter Importance\n",
    "\n",
    "Optuna can tell us to what extent each hyperparameter influences the optimization of each objective (i.e., maximization or minimization, depending on the direction defined for each objective) and the user-defined parameters. This largely depends on the range that we have defined: if the range for some hyperparameter is very restrictive, it will become very important to increase/decrease it as much as possible. Nevertheless, this visualization gives an indication of the importance of each hyperparameter and, more importantly, can reveal the inherent conflicts and synergies between the optimization objectives.\n",
    "\n",
    "In the following three cells, we plot the importance of each hyperparameter for the accuracy, the number of parameters, and the quantized model latency, respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f397e21-ffe9-4bcb-abfa-ac0c15646c0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "optuna.visualization.plot_param_importances(study, target=lambda t: t.values[0]*100, target_name=\"Accuracy (%)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fb0b999-ea8e-422f-89b1-5d981c9265ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "optuna.visualization.plot_param_importances(study, target=lambda t: t.values[1], target_name=\"Number of Parameters\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1ba61ba-b730-40a3-b891-a0bee035d953",
   "metadata": {},
   "outputs": [],
   "source": [
    "optuna.visualization.plot_param_importances(study, target=lambda t: t.user_attrs['int8_latency'], target_name=\"Latency\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
